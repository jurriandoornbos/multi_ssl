{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36acf6a3-40e1-40fc-8490-f7da7279dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e73f1a21-06bb-404d-87f5-b8b163211ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multissl.models import MSRGBConvNeXtUPerNetMixed\n",
    "from multissl.data.seg_transforms import JointTransform, ValidationJointTransform\n",
    "from multissl.data.semantic_partial_dataset import MixedSupervisionSegmentationDataset, mixed_supervision_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50f8eba2-9147-4546-897a-b5a1192d967d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from ../checkpoints_convnext_tiny/last.ckpt\n",
      "Unexpected keys: ['projection_head.layers.0.weight', 'projection_head.layers.1.weight', 'projection_head.layers.1.bias', 'projection_head.layers.1.running_mean', 'projection_head.layers.1.running_var', 'projection_head.layers.1.num_batches_tracked', 'projection_head.layers.3.weight', 'projection_head.layers.4.weight', 'projection_head.layers.4.bias', 'projection_head.layers.4.running_mean', 'projection_head.layers.4.running_var', 'projection_head.layers.4.num_batches_tracked', 'projection_head.layers.6.weight', 'projection_head.layers.7.running_mean', 'projection_head.layers.7.running_var', 'projection_head.layers.7.num_batches_tracked', 'prediction_head.layers.0.weight', 'prediction_head.layers.1.weight', 'prediction_head.layers.1.bias', 'prediction_head.layers.1.running_mean', 'prediction_head.layers.1.running_var', 'prediction_head.layers.1.num_batches_tracked', 'prediction_head.layers.3.weight', 'prediction_head.layers.3.bias']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = {\"checkpoint_path\":\"../checkpoints_convnext_tiny/last.ckpt\",\n",
    "        \"num_classes\": 62, #61+ 0 background\n",
    "        \"freeze_backbone\": True,\n",
    "        \"batch_size\": 4,\n",
    "        \"img_size\": 512,\n",
    "        \"model_size\": \"tiny\",\n",
    "        \"rgb_in_channels\": 3, #pretrained backbone setting\n",
    "        \"ms_in_channels\": 5,#pretrained backbone setting\n",
    "        \"model_size\":\"tiny\", # Can be 'tiny', 'small', 'base', 'large' #pretrained backbone setting\n",
    "        \"fusion_strategy\": \"hierarchical\", # 'early', 'late', 'hierarchical', 'progressive' #pretrained backbone setting\n",
    "        \"fusion_type\": 'attention',  # 'concat', 'add', 'attention' #pretrained backbone setting\n",
    "        \"learning_rate\": 1e3,\n",
    "        \"weight_decay\": 1e4,\n",
    "\n",
    "        \"fully_labeled_dir_train\" : \"../dataset/TreeAI/12_RGB_SemSegm_640_fL/train\",\n",
    "        \"partially_labeled_dir_train\": \"../dataset/TreeAI/34_RGB_SemSegm_640_pL/train\",\n",
    "        \"fully_labeled_dir_val\" : \"../dataset/TreeAI/12_RGB_SemSegm_640_fL/val\",\n",
    "        \"partially_labeled_dir_val\" :  \"../dataset/TreeAI/34_RGB_SemSegm_640_pL/val\",\n",
    "        \"ignore_index\" : 255, # probably just background class too :(\n",
    "        \"balance_supervision\" :  True,\n",
    "        \"partial_label_ratio\":  0.5  # W\"\n",
    "       }\n",
    "# pretrained tiny has hierarchical fusion: at every layer MS +RGB is fused with attention\n",
    "\n",
    "pl_model =  MSRGBConvNeXtUPerNetMixed(\n",
    "        num_classes=args[\"num_classes\"],  # Binary segmentation (background, foreground)\n",
    "        rgb_in_channels=args[\"rgb_in_channels\"],\n",
    "        ms_in_channels=args[\"ms_in_channels\"],\n",
    "        model_size=args['model_size'], \n",
    "        fusion_strategy=args['fusion_strategy'], \n",
    "        fusion_type=args['fusion_type'],  # 'concat', 'add', 'attention'\n",
    "        learning_rate=args[\"learning_rate\"],\n",
    "        weight_decay=args[\"weight_decay\"],\n",
    "        pretrained_backbone=args[\"checkpoint_path\"],  # Path to pretrained weights if available\n",
    "        freeze_backbone = args[\"freeze_backbone\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b487f16c-09ef-415e-903f-c2b502ef7ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2218 fully labeled samples\n",
      "Found 3126 partially labeled samples\n",
      "Final dataset size: 5344\n",
      "Dataset composition:\n",
      "  - Fully supervised: 2672 (50.0%)\n",
      "  - Partially supervised: 2672 (50.0%)\n",
      "Found 634 fully labeled samples\n",
      "Found 892 partially labeled samples\n",
      "Final dataset size: 1526\n",
      "Dataset composition:\n",
      "  - Fully supervised: 763 (50.0%)\n",
      "  - Partially supervised: 763 (50.0%)\n"
     ]
    }
   ],
   "source": [
    "train_transform = JointTransform(img_size = args[\"img_size\"], strong=True)\n",
    "val_transform = ValidationJointTransform(img_size = 640)\n",
    "\n",
    "treeai_dataset_train = MixedSupervisionSegmentationDataset(\n",
    "        fully_labeled_dir = args[\"fully_labeled_dir_train\"],\n",
    "        partially_labeled_dir = args[\"partially_labeled_dir_train\"],\n",
    "        img_size =  args[\"img_size\"],\n",
    "        transform = train_transform,\n",
    "        ignore_index= args[\"ignore_index\"],\n",
    "        num_classes =  args[\"num_classes\"],\n",
    "        balance_supervision = args[\"balance_supervision\"],\n",
    "        partial_label_ratio = args[\"partial_label_ratio\"] # W\n",
    "    \n",
    ")\n",
    "\n",
    "treeai_dataset_val = MixedSupervisionSegmentationDataset(\n",
    "        fully_labeled_dir = args[\"fully_labeled_dir_val\"],\n",
    "        partially_labeled_dir = args[\"partially_labeled_dir_val\"],\n",
    "        img_size = 640,\n",
    "        transform = val_transform,\n",
    "        ignore_index= args[\"ignore_index\"],\n",
    "        num_classes =  args[\"num_classes\"],\n",
    "        balance_supervision = args[\"balance_supervision\"],\n",
    "        partial_label_ratio = args[\"partial_label_ratio\"]\n",
    ")\n",
    "train_loader = DataLoader(treeai_dataset_train,\n",
    "                         collate_fn =mixed_supervision_collate_fn )\n",
    "val_loader = DataLoader(treeai_dataset_val,\n",
    "                       collate_fn =mixed_supervision_collate_fn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122879b3-4d93-403a-8f03-a039912efcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks\n",
    "from pytorch_lightning.callbacks import RichProgressBar, ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"treeai_checkpoints\",\n",
    "    filename=\"\",\n",
    "    save_top_k=3,\n",
    "    monitor\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "# Create logger (you can use either WandbLogger or TensorBoardLogger)\n",
    "# Comment out if you don't want to use wandb\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"TreeAI-Segmentation\", log_model=False)\n",
    "\n",
    "# Create trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=args[\"epochs\"],\n",
    "    accelerator=\"cuda\",  # Uses GPU if available\n",
    "    devices=1,\n",
    "    callbacks=[checkpoint_callback, lr_monitor, RichProgressBar()],\n",
    "    logger=wandb_logger,  # Comment out if not using wandb\n",
    "    check_val_every_n_epoch=5  # Only validate every 5 epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b152e0dd-cda7-4307-ab3f-2ee282fe1fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f367d-5792-4ae1-aa9b-5f4043ae68a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03d1b8-bd1f-4243-90fa-fae67959e0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
