epoch,step,train_loss_epoch,train_loss_step
0,0,,0.5715807676315308
0,0,0.5715807676315308,
1,1,,0.4182472229003906
1,1,0.4182472229003906,
2,2,,0.3633391261100769
2,2,0.3633391261100769,
3,3,,0.3491261601448059
3,3,0.3491261601448059,
4,4,,0.34983035922050476
4,4,0.34983035922050476,
5,5,,0.29564887285232544
5,5,0.29564887285232544,
6,6,,0.28874289989471436
6,6,0.28874289989471436,
7,7,,0.2798832654953003
7,7,0.2798832654953003,
8,8,,0.24257905781269073
8,8,0.24257905781269073,
9,9,,0.24379122257232666
9,9,0.24379122257232666,
10,10,,0.2109738141298294
10,10,0.2109738141298294,
11,11,,0.19946378469467163
11,11,0.19946378469467163,
12,12,,0.19365936517715454
12,12,0.19365936517715454,
13,13,,0.17348618805408478
13,13,0.17348618805408478,
14,14,,0.19194571673870087
14,14,0.19194571673870087,
15,15,,0.15907517075538635
15,15,0.15907517075538635,
16,16,,0.15135779976844788
16,16,0.15135779976844788,
17,17,,0.15048208832740784
17,17,0.15048208832740784,
18,18,,0.15560674667358398
18,18,0.15560674667358398,
19,19,,0.13493269681930542
19,19,0.13493269681930542,
20,20,,0.1350177526473999
20,20,0.1350177526473999,
21,21,,0.14260676503181458
21,21,0.14260676503181458,
22,22,,0.15262925624847412
22,22,0.15262925624847412,
23,23,,0.14446337521076202
23,23,0.14446337521076202,
24,24,,0.12857811152935028
24,24,0.12857811152935028,
